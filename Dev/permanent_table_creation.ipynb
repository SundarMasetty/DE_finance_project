{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ae7e30f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark Version: 3.3.0\n",
      "Hive Catalog Implementation: in-memory\n",
      "Warehouse Directory: file:/home/jupyter/spark-warehouse\n",
      "HiveContext is available\n"
     ]
    }
   ],
   "source": [
    "print(\"Spark Version:\", spark.version)\n",
    "print(\"Hive Catalog Implementation:\", spark.conf.get(\"spark.sql.catalogImplementation\"))\n",
    "print(\"Warehouse Directory:\", spark.conf.get(\"spark.sql.warehouse.dir\"))\n",
    "\n",
    "# Check if Hive classes are available\n",
    "try:\n",
    "    from pyspark.sql import HiveContext\n",
    "    print(\"HiveContext is available\")\n",
    "except ImportError:\n",
    "    print(\"HiveContext not available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7807b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hive Catalog Implementation: hive\n"
     ]
    }
   ],
   "source": [
    "spark.stop()\n",
    "# Create new SparkSession with Hive support\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"External_table_for_analysis\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .enableHiveSupport() \\\n",
    "    .config(\"spark.sql.catalogImplementation\", \"hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", \"/home/jupyter/spark-warehouse\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Verify Hive support is now enabled\n",
    "print(\"Hive Catalog Implementation:\", spark.conf.get(\"spark.sql.catalogImplementation\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d4502832",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_data_df = spark.read.format(\"parquet\").load(\"Lending_club_project/cleaned/customers_data_parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "61825309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "|           member_id|           emp_title|emp_length|home_ownership|annual_income|address_state|address_zipcode|address_country|grade|sub_grade|verification_status|total_high_credit_limit|application_type|join_annual_income|verification_status_joint|         ingest_date|\n",
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "|0d3c568ff6944b11c...|Bookkeeper/Accoun...|        10|      MORTGAGE|      48000.0|           SC|          297xx|            USA|    C|       C5|       Not Verified|               298100.0|      Individual|              null|                     null|2025-08-25 16:11:...|\n",
      "|170564954b4d02ae9...|  Billing Supervisor|        10|      MORTGAGE|      80000.0|           TX|          774xx|            USA|    C|       C5|       Not Verified|               197904.0|      Individual|              null|                     null|2025-08-25 16:11:...|\n",
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "customer_data_df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5575b406",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Namespace 'lendingclubdata' already exists",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_681/2303645440.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mspark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CREATE DATABASE lendingclubdata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msqlQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Namespace 'lendingclubdata' already exists"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE lendingclubdata\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe974ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Table or view 'customers' already exists in database 'lendingclubdata'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_681/1722582235.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mSTORED\u001b[0m \u001b[0mAS\u001b[0m \u001b[0mPARQUET\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mLOCATION\u001b[0m \u001b[0;34m'Lending_club_project/cleaned/customers_data_parquet'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \"\"\")\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# Test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/sql/session.py\u001b[0m in \u001b[0;36msql\u001b[0;34m(self, sqlQuery, **kwargs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m             \u001b[0msqlQuery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mformatter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jsparkSession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msqlQuery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/lib/py4j-0.10.9.5-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m         return_value = get_return_value(\n\u001b[0;32m-> 1322\u001b[0;31m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[0m\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1324\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mtemp_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    194\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mconverted\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Table or view 'customers' already exists in database 'lendingclubdata'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create in default database\n",
    "spark.sql(\"\"\"\n",
    "CREATE EXTERNAL TABLE lendingclubdata.customers(\n",
    "    member_id string, \n",
    "    emp_title string, \n",
    "    emp_length int, \n",
    "    home_ownership string, \n",
    "    annual_income float, \n",
    "    address_state string, \n",
    "    address_zipcode string, \n",
    "    address_country string,\n",
    "    grade string, \n",
    "    sub_grade string, \n",
    "    verification_status string, \n",
    "    total_high_credit_limit float, \n",
    "    application_type string,\n",
    "    join_annual_income float, \n",
    "    verification_status_joint string, \n",
    "    ingest_date timestamp\n",
    ") \n",
    "STORED AS PARQUET \n",
    "LOCATION 'Lending_club_project/cleaned/customers_data_parquet'\n",
    "\"\"\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22771c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here I need to create EXTERNAL TABLE as on above code but as i am working on local and having issues with hive metastore creating table which i can access across my cluster\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS lendingclubdata\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS lendingclubdata.customers\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lendingclubdata.customers (\n",
    "    member_id string, \n",
    "    emp_title string, \n",
    "    emp_length int, \n",
    "    home_ownership string, \n",
    "    annual_income float, \n",
    "    address_state string, \n",
    "    address_zipcode string, \n",
    "    address_country string,\n",
    "    grade string, \n",
    "    sub_grade string, \n",
    "    verification_status string, \n",
    "    total_high_credit_limit float, \n",
    "    application_type string,\n",
    "    join_annual_income float, \n",
    "    verification_status_joint string, \n",
    "    ingest_date timestamp\n",
    ") USING PARQUET\n",
    "LOCATION 'file:////home/jupyter/Lending_club_project/cleaned/customers_data_parquet'\n",
    "\"\"\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lendingclubdata.customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4c38644d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "|           member_id|           emp_title|emp_length|home_ownership|annual_income|address_state|address_zipcode|address_country|grade|sub_grade|verification_status|total_high_credit_limit|application_type|join_annual_income|verification_status_joint|         ingest_date|\n",
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "|0d3c568ff6944b11c...|Bookkeeper/Accoun...|        10|      MORTGAGE|      48000.0|           SC|          297xx|            USA|    C|       C5|       Not Verified|               298100.0|      Individual|              null|                     null|2025-08-25 16:11:...|\n",
      "|170564954b4d02ae9...|  Billing Supervisor|        10|      MORTGAGE|      80000.0|           TX|          774xx|            USA|    C|       C5|       Not Verified|               197904.0|      Individual|              null|                     null|2025-08-25 16:11:...|\n",
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lendingclubdata.customers\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "093a7a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+---------------+-------+\n",
      "|col_name                    |data_type      |comment|\n",
      "+----------------------------+---------------+-------+\n",
      "|member_id                   |string         |null   |\n",
      "|emp_title                   |string         |null   |\n",
      "|emp_length                  |int            |null   |\n",
      "|home_ownership              |string         |null   |\n",
      "|annual_income               |float          |null   |\n",
      "|address_state               |string         |null   |\n",
      "|address_zipcode             |string         |null   |\n",
      "|address_country             |string         |null   |\n",
      "|grade                       |string         |null   |\n",
      "|sub_grade                   |string         |null   |\n",
      "|verification_status         |string         |null   |\n",
      "|total_high_credit_limit     |float          |null   |\n",
      "|application_type            |string         |null   |\n",
      "|join_annual_income          |float          |null   |\n",
      "|verification_status_joint   |string         |null   |\n",
      "|ingest_date                 |timestamp      |null   |\n",
      "|                            |               |       |\n",
      "|# Detailed Table Information|               |       |\n",
      "|Database                    |lendingclubdata|       |\n",
      "|Table                       |customers      |       |\n",
      "+----------------------------+---------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"DESCRIBE formatted lendingclubdata.customers\").show(truncate= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38576a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Loans data \n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS lendingclubdata\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS lendingclubdata.loans\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lendingclubdata.loans(loan_id string, member_id string, loan_amnt float, funded_amnt float, loan_term_months string,\n",
    "           interest_rate float, monthly_installment float, issue_date string, loan_status string, \n",
    "          loan_purpose string, loan_title string, ingested_time timestamp)\n",
    "          USING PARQUET LOCATION 'file:////home/jupyter/Lending_club_project/cleaned/loan_data_parquet'\n",
    "          \"\"\")\n",
    "spark.sql(\"REFRESH TABLE lendingclubdata.loans\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b73ebff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+-----------+----------------+-------------+-------------------+----------+-----------+------------------+------------------+--------------------+\n",
      "|  loan_id|           member_id|loan_amnt|funded_amnt|loan_term_months|interest_rate|monthly_installment|issue_date|loan_status|      loan_purpose|        loan_title|       ingested_time|\n",
      "+---------+--------------------+---------+-----------+----------------+-------------+-------------------+----------+-----------+------------------+------------------+--------------------+\n",
      "|130943487|51989e17caab932ca...|   4800.0|     4800.0|            null|        15.04|             166.49|  Mar-2018| Fully Paid|           medical|  Medical expenses|2025-08-26 00:17:...|\n",
      "|130514193|043da8398b63b2c44...|  40000.0|    40000.0|            null|        14.07|             932.19|  Mar-2018|    Current|debt_consolidation|Debt consolidation|2025-08-26 00:17:...|\n",
      "+---------+--------------------+---------+-----------+----------------+-------------+-------------------+----------+-----------+------------------+------------------+--------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT * FROM lendingclubdata.loans\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8db27bb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|  loan_id|total_principal_received|total_interest_received|total_late_fee_received|total_payment_received|last_payment_amount|last_payment_date|next_payment_date|         ingest_date|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "|113619662|                  7500.0|                 357.79|                    0.0|              7857.791|            6642.78|         Feb-2018|             null|2025-08-26 11:43:...|\n",
      "|111985436|                15937.81|                3123.29|                    0.0|               19061.1|            1002.33|         Feb-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113569389|                10106.07|                3470.43|                    0.0|               13576.5|             679.58|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113855914|                  6000.0|                 894.66|                    0.0|              6894.661|            3840.99|         Nov-2018|             null|2025-08-26 11:43:...|\n",
      "|113839616|                 2799.97|                2226.58|                    0.0|               5026.55|             251.75|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113529525|                 2244.02|                 831.44|                    0.0|               3075.46|             147.71|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113851343|                 4400.78|                1155.75|                    0.0|               5556.53|             292.19|         Feb-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|112729968|                  4230.9|                  721.7|                    0.0|                4952.6|             247.79|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|114073825|                 5525.27|                5220.64|                    0.0|              10745.91|             538.28|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|114171262|                 8329.71|                1906.54|                    0.0|              10236.25|             512.08|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113684273|                 2526.63|                 867.59|                    0.0|               3394.22|              169.9|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|114023823|                 2143.41|                 264.61|                    0.0|               2408.02|             120.46|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113307810|                 25000.0|                1280.65|                    0.0|             26280.654|           14692.13|         Feb-2018|             null|2025-08-26 11:43:...|\n",
      "|113876028|                 16000.0|                1278.58|                    0.0|             17278.582|           15735.78|         Dec-2017|             null|2025-08-26 11:43:...|\n",
      "|113881466|                  1600.0|                 131.63|                    0.0|             1731.6311|             939.31|         Dec-2018|             null|2025-08-26 11:43:...|\n",
      "|113206202|                 5741.09|                 1478.7|                    0.0|               7219.79|             335.12|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113541874|                10230.05|                2833.32|                    0.0|              13063.37|             686.62|         Feb-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113608833|                 5112.03|                1523.31|                    0.0|               6635.34|              332.1|         Mar-2019|         Apr-2019|2025-08-26 11:43:...|\n",
      "|113618697|                  9000.0|                1671.37|                    0.0|             10671.366|            5371.32|         Jan-2019|             null|2025-08-26 11:43:...|\n",
      "|113811106|                 20000.0|                1561.37|                    0.0|              21561.37|           13426.25|         Sep-2018|             null|2025-08-26 11:43:...|\n",
      "+---------+------------------------+-----------------------+-----------------------+----------------------+-------------------+-----------------+-----------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Loan repayments data\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS lendingclubdata\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS lendingclubdata.loan_repayments\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lendingclubdata.loan_repayments(loan_id string,total_principal_received float,total_interest_received float,\n",
    "          total_late_fee_received float,total_payment_received float,last_payment_amount float,last_payment_date string,\n",
    "          next_payment_date string,ingest_date timestamp) \n",
    "          USING PARQUET LOCATION 'file:////home/jupyter/Lending_club_project/cleaned/loan_repayments_parquet' \"\"\")\n",
    "\n",
    "spark.sql(\"REFRESH TABLE lendingclubdata.loan_repayments\")\n",
    "spark.sql(\"SELECT * FROM lendingclubdata.loan_repayments\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c191f2d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-----------+-----------+----------------------+\n",
      "|           member_id|delinq_2yrs|delinq_amnt|mths_since_last_delinq|\n",
      "+--------------------+-----------+-----------+----------------------+\n",
      "|680fb82b4acb97795...|          0|        0.0|                    24|\n",
      "|0e0a6f18a90718c2a...|          0|        0.0|                    54|\n",
      "+--------------------+-----------+-----------+----------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#loan delinquers\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS lendingclubdata\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS lendingclubdata.delinq\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lendingclubdata.delinq(member_id string,delinq_2yrs integer,delinq_amnt float,mths_since_last_delinq integer )\n",
    "          USING PARQUET LOCATION 'file:////home/jupyter/Lending_club_project/cleaned/loans_defaulters_delinq_parquet' \"\"\")\n",
    "spark.sql(\"REFRESH TABLE lendingclubdata.delinq\")\n",
    "spark.sql(\"SELECT * FROM lendingclubdata.delinq\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "84083fec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+--------------+\n",
      "|           member_id|pub_rec|pub_rec_bankruptcies|inq_last_6mths|\n",
      "+--------------------+-------+--------------------+--------------+\n",
      "|5c18f413cebed2192...|      1|                   1|             0|\n",
      "|e98eb408f9863ef59...|      0|                   0|             0|\n",
      "+--------------------+-------+--------------------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS lendingclubdata\")\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "DROP TABLE IF EXISTS lendingclubdata.loan_defaulters_detail_rec\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "CREATE TABLE lendingclubdata.loan_defaulters_detail_rec(member_id string, pub_rec int, pub_rec_bankruptcies int, inq_last_6mths int) USING PARQUET LOCATION 'file:////home/jupyter/Lending_club_project/cleaned/loans_defaulters_detailed_records_parquet'\"\"\")\n",
    "spark.sql(\"REFRESH TABLE lendingclubdata.loan_defaulters_detail_rec\")\n",
    "spark.sql(\"SELECT * FROM lendingclubdata.loan_defaulters_detail_rec\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "061bfe8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------------------------+-----------+\n",
      "|namespace      |tableName                 |isTemporary|\n",
      "+---------------+--------------------------+-----------+\n",
      "|lendingclubdata|customers                 |false      |\n",
      "|lendingclubdata|delinq                    |false      |\n",
      "|lendingclubdata|loan_defaulters_detail_rec|false      |\n",
      "|lendingclubdata|loan_repayments           |false      |\n",
      "|lendingclubdata|loans                     |false      |\n",
      "+---------------+--------------------------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"show TABLES FROM lendingclubdata \").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ad3abf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
