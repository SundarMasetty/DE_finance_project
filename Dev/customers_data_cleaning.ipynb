{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e6f0917",
   "metadata": {},
   "source": [
    "###### 1. dataframe with proper datatype 2.renaming few columns as per our convienience 3.Inserting ingestion date column as a current timestamp. 4.removing duplicate rows\n",
    "###### 5. Remove rows where annual income is NULL 6.convert emp_length to INTEGER 6.Average of emp_length with NULLS 8.Only need 2 letters for address state remove the misc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"LendingClubProject_DC\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "600aaa8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://3af7bb76653c:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>LendingClubProject_DC</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x2aaae6a742d0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d6db3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_raw_df = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\",\"true\").load(\"Lending_club_project/raw/customers_data_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea456edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- member_id: string (nullable = true)\n",
      " |-- emp_title: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: string (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- tot_hi_cred_lim: double (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- annual_inc_joint: string (nullable = true)\n",
      " |-- verification_status_joint: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e12fc79",
   "metadata": {},
   "source": [
    "##### Need schema with proper datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc806b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, StringType, FloatType\n",
    "\n",
    "cust_schema = StructType([\n",
    "    StructField(\"member_id\", StringType(), True),\n",
    "    StructField(\"emp_title\", StringType(), True),\n",
    "    StructField(\"emp_length\", StringType(), True),\n",
    "    StructField(\"home_ownership\", StringType(), True),\n",
    "    StructField(\"annual_inc\", FloatType(), True),\n",
    "    StructField(\"addr_state\", StringType(), True),\n",
    "    StructField(\"zip_code\", StringType(), True),\n",
    "    StructField(\"country\", StringType(), True),\n",
    "    StructField(\"grade\", StringType(), True),\n",
    "    StructField(\"sub_grade\", StringType(), True),\n",
    "    StructField(\"verification_status\", StringType(), True),\n",
    "    StructField(\"tot_hi_cred_lim\", FloatType(), True),\n",
    "    StructField(\"application_type\", StringType(), True),\n",
    "    StructField(\"annual_inc_joint\", FloatType(), True),\n",
    "    StructField(\"verification_status_joint\", StringType(), True)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0439a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_raw_df = spark.read.format(\"csv\").option(\"header\",\"true\").schema(cust_schema).load(\"Lending_club_project/raw/customers_data_csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8e89ec43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- member_id: string (nullable = true)\n",
      " |-- emp_title: string (nullable = true)\n",
      " |-- emp_length: string (nullable = true)\n",
      " |-- home_ownership: string (nullable = true)\n",
      " |-- annual_inc: float (nullable = true)\n",
      " |-- addr_state: string (nullable = true)\n",
      " |-- zip_code: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- grade: string (nullable = true)\n",
      " |-- sub_grade: string (nullable = true)\n",
      " |-- verification_status: string (nullable = true)\n",
      " |-- tot_hi_cred_lim: float (nullable = true)\n",
      " |-- application_type: string (nullable = true)\n",
      " |-- annual_inc_joint: float (nullable = true)\n",
      " |-- verification_status_joint: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cust_raw_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2a684160",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+\n",
      "|           member_id|           emp_title|emp_length|home_ownership|annual_income|address_state|address_zipcode|address_country|grade|sub_grade|verification_status|total_high_credit_limit|application_type|join_annual_income|verification_status_joint|\n",
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+\n",
      "|6d5091b3fcaaeb4ea...|             leadman| 10+ years|      MORTGAGE|      55000.0|           PA|          190xx|            USA|    C|       C4|       Not Verified|               178050.0|      Individual|              null|                     null|\n",
      "|b5e7938b0a2da4cea...|            Engineer| 10+ years|      MORTGAGE|      65000.0|           SD|          577xx|            USA|    C|       C1|       Not Verified|               314017.0|      Individual|              null|                     null|\n",
      "|91060b858433e8a61...|        truck driver| 10+ years|      MORTGAGE|      63000.0|           IL|          605xx|            USA|    B|       B4|       Not Verified|               218418.0|       Joint App|           71000.0|             Not Verified|\n",
      "|cab1fa9f533688b0a...|Information Syste...| 10+ years|      MORTGAGE|     110000.0|           NJ|          076xx|            USA|    C|       C5|    Source Verified|               381215.0|      Individual|              null|                     null|\n",
      "|f74e401c1ab0adf78...| Contract Specialist|   3 years|      MORTGAGE|     104433.0|           PA|          174xx|            USA|    F|       F1|    Source Verified|               439570.0|      Individual|              null|                     null|\n",
      "|8aef4bb29d609d8d6...|Veterinary Tecnician|   4 years|          RENT|      34000.0|           GA|          300xx|            USA|    C|       C3|    Source Verified|                16900.0|      Individual|              null|                     null|\n",
      "|538b4653da3b1e814...|Vice President of...| 10+ years|      MORTGAGE|     180000.0|           MN|          550xx|            USA|    B|       B2|       Not Verified|               388852.0|      Individual|              null|                     null|\n",
      "|b24d55f21390533c5...|         road driver| 10+ years|      MORTGAGE|      85000.0|           SC|          293xx|            USA|    B|       B1|       Not Verified|               193390.0|      Individual|              null|                     null|\n",
      "|1035c5401b0ca76d0...|     SERVICE MANAGER|   6 years|          RENT|      85000.0|           PA|          160xx|            USA|    A|       A2|       Not Verified|                61099.0|      Individual|              null|                     null|\n",
      "|cb0f1777593e77909...|      Vendor liaison| 10+ years|      MORTGAGE|      42000.0|           RI|          029xx|            USA|    B|       B5|       Not Verified|               256513.0|      Individual|              null|                     null|\n",
      "|a962f4d59caec5fa1...|  Executive Director|   6 years|      MORTGAGE|      95000.0|           SC|          290xx|            USA|    C|       C2|       Not Verified|               436841.0|      Individual|              null|                     null|\n",
      "|e7592ab57b3afd9f1...|Senior Structural...|    1 year|      MORTGAGE|      70000.0|           TX|          786xx|            USA|    C|       C2|       Not Verified|               309638.0|      Individual|              null|                     null|\n",
      "|603afa9d1be879b7b...|   Logistics Manager|   3 years|      MORTGAGE|      64000.0|           NC|          275xx|            USA|    C|       C2|       Not Verified|               372109.0|      Individual|              null|                     null|\n",
      "|9fe2d59ddf2a4f37e...|    Software Manager|   7 years|          RENT|     150000.0|           CA|          916xx|            USA|    E|       E2|       Not Verified|                65819.0|      Individual|              null|                     null|\n",
      "|23857480ccf555ce4...|      Senior Manager| 10+ years|      MORTGAGE|      92000.0|           NC|          275xx|            USA|    A|       A2|       Not Verified|               304003.0|      Individual|              null|                     null|\n",
      "|7c69d5f36fdabf6e1...|                tech|   8 years|      MORTGAGE|      60000.0|           SC|          299xx|            USA|    A|       A4|       Not Verified|                88635.0|      Individual|              null|                     null|\n",
      "|08bf9e080503b0113...|       Sales Manager| 10+ years|      MORTGAGE|     109000.0|           VA|          226xx|            USA|    A|       A4|       Not Verified|               373572.0|      Individual|              null|                     null|\n",
      "|1cafb05aa6c894c30...|               GS-11| 10+ years|      MORTGAGE|     112000.0|           AZ|          856xx|            USA|    C|       C1|       Not Verified|               309710.0|      Individual|              null|                     null|\n",
      "|f2c4010f700d8c9c4...|             Teacher|   5 years|          RENT|      64000.0|           NY|          117xx|            USA|    B|       B1|       Not Verified|                93962.0|      Individual|              null|                     null|\n",
      "|05ad4aed7c393035e...| Program Coordinator|   8 years|          RENT|      55000.0|           IN|          462xx|            USA|    E|       E3|           Verified|                38998.0|      Individual|              null|                     null|\n",
      "+--------------------+--------------------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Renaming the Columns\n",
    "# Defining  a dictionary mapping old column names to new names\n",
    "rename_map = {\n",
    "    \"annual_inc\": \"annual_income\",\n",
    "    \"addr_state\": \"address_state\",\n",
    "    \"zip_code\":\"address_zipcode\",\n",
    "    \"country\":\"address_country\",\n",
    "    \"tot_hi_cred_lim\":\"total_high_credit_limit\",\n",
    "    \"annual_inc_joint\":\"join_annual_income\"\n",
    "}\n",
    "\n",
    "# Apply renames cumulatively\n",
    "renamed_df = cust_raw_df\n",
    "for old_name, new_name in rename_map.items():\n",
    "    renamed_df = renamed_df.withColumnRenamed(old_name, new_name)\n",
    "\n",
    "renamed_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "990c5256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Current ingestion timestamp\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "time_df = renamed_df.withColumn(\"ingest_date\",current_timestamp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8cdda4ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+---------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "|           member_id|emp_title|emp_length|home_ownership|annual_income|address_state|address_zipcode|address_country|grade|sub_grade|verification_status|total_high_credit_limit|application_type|join_annual_income|verification_status_joint|         ingest_date|\n",
      "+--------------------+---------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "|6d5091b3fcaaeb4ea...|  leadman| 10+ years|      MORTGAGE|      55000.0|           PA|          190xx|            USA|    C|       C4|       Not Verified|               178050.0|      Individual|              null|                     null|2025-08-25 11:52:...|\n",
      "+--------------------+---------+----------+--------------+-------------+-------------+---------------+---------------+-----+---------+-------------------+-----------------------+----------------+------------------+-------------------------+--------------------+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "time_df.show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3219e838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717922"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "23f6e06c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717912"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad27f519",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_cust = time_df.distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aed0a694",
   "metadata": {},
   "outputs": [],
   "source": [
    "unq_cust.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6280bca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+\n",
      "|count(1)|\n",
      "+--------+\n",
      "|  717912|\n",
      "+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) from customers\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2030b2db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|Null_income_values|\n",
      "+------------------+\n",
      "|                 2|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select count(*) AS Null_income_values from customers where annual_income is NULL\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8963e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_income_filtered = spark.sql(\"SELECT * FROM customers where annual_income is NOT NULL \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e0c92b84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "717910"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customers_income_filtered.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b0ffc532",
   "metadata": {},
   "outputs": [],
   "source": [
    "customers_income_filtered.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "68ec65eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "|emp_length|\n",
      "+----------+\n",
      "|   5 years|\n",
      "|   9 years|\n",
      "|      null|\n",
      "|    1 year|\n",
      "|   2 years|\n",
      "|   7 years|\n",
      "|   8 years|\n",
      "|   4 years|\n",
      "|   6 years|\n",
      "|   3 years|\n",
      "| 10+ years|\n",
      "|  < 1 year|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT DISTINCT(emp_length) FROM customers\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0946495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method DataFrame.printSchema of DataFrame[member_id: string, emp_title: string, emp_length: int, home_ownership: string, annual_income: float, address_state: string, address_zipcode: string, address_country: string, grade: string, sub_grade: string, verification_status: string, total_high_credit_limit: float, application_type: string, join_annual_income: float, verification_status_joint: string, ingest_date: timestamp]>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Replace Nulls with avg of emp_length , and make it integer \n",
    "from pyspark.sql.functions import regexp_replace , col\n",
    "emp_cleaned = customers_income_filtered.withColumn(\"emp_length\", regexp_replace(col(\"emp_length\"),\"(\\D)\",\"\").cast(\"int\")) # If its not a digit it will be replaced with \n",
    "emp_cleaned.printSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "973c0ac2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45932"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_cleaned.filter(\"emp_length IS NULL\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e560a8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_cleaned.createOrReplaceTempView(\"customers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c08e538a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+\n",
      "|avg_emp_length|\n",
      "+--------------+\n",
      "|             6|\n",
      "+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"SELECT floor(AVG(emp_length)) as avg_emp_length FROM customers\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "09e614ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Collecting the average emp_length\n",
    "avg_emp_length = spark.sql(\"SELECT floor(AVG(emp_length)) as avg_emp_length FROM customers\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4b87cf2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(avg_emp_length=6)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_emp_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "12a9eefb",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = avg_emp_length[0]  # to access only the value we can also use avg_emp_length[0][0]\n",
    "avg_emp_duration = row['avg_emp_length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8b181b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|null_salary|\n",
      "+-----------+\n",
      "|          0|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Filling nulls with the average emp_length\n",
    "cust_emp_length_fixed_df =emp_cleaned.fillna(avg_emp_duration,subset=['emp_length'])\n",
    "cust_emp_length_fixed_df.createOrReplaceTempView(\"customers\")\n",
    "spark.sql(\"Select count(*) as null_salary from customers where emp_length IS NULL \").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "8b646f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+\n",
      "|     address_state|\n",
      "+------------------+\n",
      "|debt_consolidation|\n",
      "+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"select DISTINCT(address_state) FROM customers where length(address_state) > 2\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "19d10302",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|address_state|\n",
      "+-------------+\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when, col,length\n",
    "cust_state_fixed=cust_emp_length_fixed_df.withColumn(\"address_state\",when(length(col(\"address_state\"))>2,\"NA\").otherwise(col(\"address_state\"))\n",
    "                                                     )\n",
    "cust_state_fixed.select(\"address_state\").filter(length(\"address_state\")>2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c1a79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_state_fixed.write.format(\"parquet\").mode(\"overwrite\")\\\n",
    ".option(\"path\",\"Lending_club_project/cleaned/customers_data_parquet\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "268c2cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "cust_state_fixed.repartition(1).write.format(\"csv\").mode(\"overwrite\").option(\"header\",\"True\")\\\n",
    ".option(\"path\",\"Lending_club_project/cleaned/csv/customers_data_csv\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8141c27b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
